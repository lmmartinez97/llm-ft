{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Global imports\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Typing import\n",
    "from typing import List, Dict, Union, Tuple\n",
    "\n",
    "# Specific imports\n",
    "from copy import deepcopy\n",
    "from matplotlib.patches import Rectangle, Ellipse\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from rich import print\n",
    "from termcolor import cprint\n",
    "\n",
    "# Local imports\n",
    "from loading import csv_to_dict\n",
    "\n",
    "sns.set_theme('notebook')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.color_palette(\"hls\", 8)\n",
    "\n",
    "def print_bl():\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_red(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"red\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n",
    "\n",
    "def print_green(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"green\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n",
    "\n",
    "def print_highlight(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"magenta\", \"on_white\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n",
    "\n",
    "def print_blue(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"light_blue\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group definition:\n",
    "- 1 second sampling rate.\n",
    "- In any scene, choose an ego vehicle __outside__ of the roundabout. That is the ego vehicle.\n",
    "    - Sample the database until the ego vehicle enters the roundabout\n",
    "    - If window length is short, resample the same scene with another ego_vehicle. If there are not any suitable vehicles, move on.\n",
    "- Max window length: 5 seconds.\n",
    "\n",
    "Refer all coordinates to the center of the roundabout. Perform calculations in pixels and then convert to meters using OrthoPxToMeter*10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RounDGroupExtractor:\n",
    "    \"\"\"\n",
    "    A class that extracts vehicle groups from a rounD dataset recording, specifically focusing on \n",
    "    vehicles entering and navigating through a roundabout.\n",
    "\n",
    "    Attributes:\n",
    "        dataset_location (str): Path to the directory where the dataset is stored.\n",
    "        dataset_index (int): Index of the recording to be processed (must be between 1 and 22).\n",
    "        data (pd.DataFrame): Raw vehicle trajectory data from the recording.\n",
    "        static_info (pd.DataFrame): Static information about the vehicles.\n",
    "        video_info (dict): Metadata about the video recording, including frame rate and scaling factor.\n",
    "        sampling_period (int): Time interval between frames to include in the analysis.\n",
    "        frame_spacing (int): Number of frames between each sampled frame.\n",
    "        frame_length (float): Duration of each frame in milliseconds.\n",
    "        framing_dict (Dict[int, int]): Dictionary mapping new frame numbers to original frame numbers.\n",
    "        raw_frames (pd.Series): Original frame numbers before filtering.\n",
    "        bg_image (np.ndarray): Background image for plotting and analysis.\n",
    "        bg_image_scaling_factor (float): Scaling factor for converting pixel coordinates to meters.\n",
    "        center_x_px (int): X-coordinate of the roundabout center in pixels.\n",
    "        center_y_px (int): Y-coordinate of the roundabout center in pixels.\n",
    "        outer_radius_px (int): Radius of the outer edge of the roundabout in pixels.\n",
    "        inner_radius_px (int): Radius of the inner edge of the roundabout in pixels.\n",
    "        center_x_m (float): X-coordinate of the roundabout center in meters.\n",
    "        center_y_m (float): Y-coordinate of the roundabout center in meters.\n",
    "        outer_radius_m (float): Radius of the outer edge of the roundabout in meters.\n",
    "        inner_radius_m (float): Radius of the inner edge of the roundabout in meters.\n",
    "        entry_points_px (Dict[str, Tuple[int, int]]): Entry points of the roundabout in pixels.\n",
    "        exit_points_px (Dict[str, Tuple[int, int]]): Exit points of the roundabout in pixels.\n",
    "        entry_points_m (Dict[str, Tuple[float, float]]): Entry points of the roundabout in meters.\n",
    "        exit_points_m (Dict[str, Tuple[float, float]]): Exit points of the roundabout in meters.\n",
    "        rotation_angle (float): Angle of rotation for aligning the roundabout arms with the x-axis.\n",
    "        entry_points_m_new (Dict[str, Tuple[float, float]]): Translated and rotated entry points in meters.\n",
    "        exit_points_m_new (Dict[str, Tuple[float, float]]): Translated and rotated exit points in meters.\n",
    "        \n",
    "    Methods:\n",
    "        get_background_img(path): Loads the background image for plotting and geometry calculations.\n",
    "        get_roundabout_edges(): Detects the roundabout's center and the radii of the inner and outer edges.\n",
    "        get_entry_exit_points(): Calculates the roundaboutâ€™s entry and exit points using homography.\n",
    "        plot_roundabout_geometry_and_points(rotate): Plots the roundabout geometry and optionally rotates it.\n",
    "        in_roundabout(x, y): Checks if a given point (x, y) is within the roundabout's boundaries.\n",
    "        filter_data(sampling_period): Filters the dataset based on a specified sampling period.\n",
    "        translate(): Translates and rotates vehicle positions to align the roundabout with the x-axis.\n",
    "        get_ego_vehicles(entry_radius): Identifies vehicles entering the roundabout and logs their entry frame and point.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_location: str = None, dataset_index: int = None) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the RounDGroupExtractor class for processing a specific dataset recording.\n",
    "\n",
    "        This constructor sets up the necessary attributes for analyzing vehicle trajectories around a roundabout. \n",
    "        It loads the dataset's raw data, static vehicle information, and video metadata, and prepares the background \n",
    "        image for plotting and geometric calculations. The roundabout's center, inner/outer radii, and entry/exit points \n",
    "        are also initialized, and homography is applied to align the current image with reference data.\n",
    "\n",
    "        Args:\n",
    "            dataset_location (str): The path to the directory where the dataset is stored.\n",
    "            dataset_index (int): The index of the recording to process (must be between 1 and 22).\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no dataset location is provided or if the dataset index is outside the valid range.\n",
    "        \"\"\"\n",
    "        ### Error handling\n",
    "        if dataset_location is None:\n",
    "            raise ValueError(\"Please provide a dataset location.\")\n",
    "        if dataset_index is None or dataset_index < 1 or dataset_index > 22:\n",
    "            raise ValueError(\"Please provide a dataset index between 1 and 22\")\n",
    "        \n",
    "        # Reference points for homography\n",
    "        self.reference_exit_points = {'north': (961,238), 'south': (645, 695), 'east': (1053, 590), 'west': (550, 354)}\n",
    "        self.reference_entry_points = {'north': (880, 195), 'south': (724, 735), 'east': (1083, 503), 'west': (528, 439)}\n",
    "        self.reference_rotation_angle = 14.25\n",
    "\n",
    "        # Entry and exit points for the current image - Initialized in get_entry_exit_points\n",
    "        self.entry_points = {}\n",
    "        self.exit_points = {}\n",
    "        self.rotation_angle = 0.0\n",
    "\n",
    "        # retrieve raw data\n",
    "        self.dataset_index  = dataset_index\n",
    "        self.dataset_location = dataset_location\n",
    "        self.df_location = dataset_location + str(dataset_index).zfill(2) + \"_tracks.csv\"\n",
    "        self.static_info_location = dataset_location + str(dataset_index).zfill(2) + \"_tracksMeta.csv\"\n",
    "        self.video_info_location = dataset_location + str(dataset_index).zfill(2) + \"_recordingMeta.csv\"\n",
    "        self.reference_image_path = dataset_location + '00_background.png'\n",
    "        self.image_path = dataset_location + f'{str(dataset_index).zfill(2)}_background.png'\n",
    "\n",
    "        self.data = pd.read_csv(self.df_location)\n",
    "        self.raw_data = deepcopy(self.data)\n",
    "        self.static_info = pd.read_csv(self.static_info_location)\n",
    "        self.video_info = csv_to_dict(self.video_info_location)\n",
    "\n",
    "        self.frame_length = 1000/self.video_info[\"frameRate\"] # Measured in miliseconds\n",
    "\n",
    "        # get dictionary with keys as trackId and values as class\n",
    "        self.vehicle_type = dict(zip(self.static_info.trackId, self.static_info['class']))\n",
    "        self.restricted_vehicle_types = ['pedestrian', 'bicycle']\n",
    "\n",
    "        self.get_background_img(self.image_path)\n",
    "        self.center_x_px, self.center_y_px, self.outer_radius_px, self.inner_radius_px = self.get_roundabout_edges()\n",
    "        self.entry_points_px, self.exit_points_px = self.get_entry_exit_points()\n",
    "\n",
    "        # Convert pixel values to meters\n",
    "        self.center_x_m = self.center_x_px * self.bg_image_scaling_factor\n",
    "        self.center_y_m = -self.center_y_px * self.bg_image_scaling_factor\n",
    "        self.outer_radius_m = self.outer_radius_px * self.bg_image_scaling_factor\n",
    "        self.inner_radius_m = self.inner_radius_px * self.bg_image_scaling_factor\n",
    "        self.entry_points_m = {key: (point[0] * self.bg_image_scaling_factor, -point[1] * self.bg_image_scaling_factor) for key, point in self.entry_points_px.items()}\n",
    "        self.exit_points_m = {key: (point[0] * self.bg_image_scaling_factor, -point[1] * self.bg_image_scaling_factor) for key, point in self.exit_points_px.items()}\n",
    "\n",
    "        self.ego_vehicles = {}\n",
    " \n",
    "    def get_background_img(self, path) -> None:\n",
    "        \"\"\"\n",
    "        Loads the background image for plotting and analysis.\n",
    "\n",
    "        Args:\n",
    "            path (str): Path to the PNG image file containing the background image.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the background image is not found at the specified path.\n",
    "\n",
    "        Initializes the image scaling factor (meters per pixel) using data from the video information. \n",
    "        From experimentation, this factor needs to be multiplied by 10 to match the roundabout geometry.\n",
    "        \"\"\"\n",
    "        ### Error handling\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Background image not found at {path}.\")\n",
    "        self.bg_image = cv2.imread(path)\n",
    "        self.bg_image_scaling_factor = self.video_info[\"orthoPxToMeter\"]*10 # Measured in meters per pixel\n",
    "\n",
    "    def get_roundabout_edges(self) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"\n",
    "        Detects the outer and inner edges of the roundabout using HoughCircles.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[int, int, int, int]: A tuple containing the X and Y coordinates of the roundabout center, \n",
    "            and the radii of the outer and inner circles, respectively.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no outer or inner edge is detected.\n",
    "        \"\"\"\n",
    "\n",
    "        gray = cv2.cvtColor(self.bg_image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 7), 0)\n",
    "\n",
    "        # Use HoughCircles to detect the roundabout's outer edge\n",
    "        outer_circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=1000,\n",
    "            param1=100, param2=30, minRadius=200, maxRadius=300\n",
    "        )\n",
    "\n",
    "        if outer_circles is not None:\n",
    "            outer_circles = np.round(outer_circles[0, :]).astype(\"int\")\n",
    "            largest_circle = max(outer_circles, key=lambda x: x[2])  # Select the largest circle (outer edge)\n",
    "            center_x, center_y, outer_radius = largest_circle\n",
    "\n",
    "            # Detect inner edge using a smaller radius range\n",
    "            inner_circles = cv2.HoughCircles(\n",
    "                blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=300,\n",
    "                param1=100, param2=30, minRadius=100, maxRadius=outer_radius - 50\n",
    "            )\n",
    "\n",
    "            if inner_circles is not None:\n",
    "                inner_circles = np.round(inner_circles[0, :]).astype(\"int\")\n",
    "                inner_center_x, inner_center_y, inner_radius = min(inner_circles, key=lambda x: abs(x[0] - center_x))\n",
    "                return center_x, center_y, outer_radius, inner_radius\n",
    "\n",
    "        raise ValueError(\"No outer or inner edge detected.\")\n",
    "\n",
    "    def get_entry_exit_points(self) -> Tuple[Dict[str, Tuple[int, int]], Dict[str, Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Calculates the entry and exit points of the roundabout based on homography transformations.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Dict[str, Tuple[int, int]], Dict[str, Tuple[int, int]]]: Two dictionaries containing the \n",
    "            entry and exit points for the roundabout, where each key is the name of an entry/exit point \n",
    "            ('north', 'south', 'east', 'west') and each value is a tuple of pixel coordinates.\n",
    "        \"\"\"\n",
    "        reference_image = cv2.imread(self.reference_image_path)\n",
    "        current_image = cv2.imread(self.image_path)\n",
    "\n",
    "        gray_reference = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)\n",
    "        gray_current = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Feature matching with SIFT\n",
    "        sift = cv2.SIFT_create()\n",
    "        kp_ref, des_ref = sift.detectAndCompute(gray_reference, None)\n",
    "        kp_cur, des_cur = sift.detectAndCompute(gray_current, None)\n",
    "\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        matches = bf.match(des_ref, des_cur)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        ref_pts = np.float32([kp_ref[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        cur_pts = np.float32([kp_cur[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Compute homography matrix\n",
    "        H, _ = cv2.findHomography(ref_pts, cur_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        self.rotation_angle = np.atan2(H[0, 1], H[0, 0]) * 180 / np.pi + self.reference_rotation_angle\n",
    "\n",
    "        reference_entry_points = np.float32(list(self.reference_entry_points.values())).reshape(-1, 1, 2)\n",
    "        reference_exit_points = np.float32(list(self.reference_exit_points.values())).reshape(-1, 1, 2)\n",
    "\n",
    "        transformed_entry_points = cv2.perspectiveTransform(reference_entry_points, H)\n",
    "        transformed_exit_points = cv2.perspectiveTransform(reference_exit_points, H)\n",
    "\n",
    "        entry_points = {key: tuple(point[0]) for key, point in zip(self.reference_entry_points.keys(), transformed_entry_points)}\n",
    "        exit_points = {key: tuple(point[0]) for key, point in zip(self.reference_exit_points.keys(), transformed_exit_points)}\n",
    "\n",
    "        return entry_points, exit_points\n",
    "    \n",
    "    def in_roundabout(self, x: float, y: float) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if a point is inside the roundabout.\n",
    "        \n",
    "        Args:\n",
    "            x (float): X-coordinate of the point.\n",
    "            y (float): Y-coordinate of the point.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if the point is inside the outer radius and outside the inner radius, False otherwise.\n",
    "        \"\"\"\n",
    "        distance_to_center = np.linalg.norm(np.array([x, y]) - np.array([self.center_x_m, self.center_y_m]))\n",
    "        return self.inner_radius_m <= distance_to_center <= self.outer_radius_m\n",
    "    \n",
    "    def filter_data(self, sampling_period: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filters the dataset based on a specified sampling period.\n",
    "        Translates and rotates the data to align the roundabout arms with the x-axis.\n",
    "\n",
    "        Args:\n",
    "            sampling_period (int): The time interval between frames to include, in milliseconds.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing only the frames that match the sampling period.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the sampling period is not a multiple of the frame duration (40 ms).\n",
    "\n",
    "        This method adjusts the frame numbering and generates a dictionary to map new frame numbers \n",
    "        to their original values. The resulting DataFrame only contains frames spaced according to the \n",
    "        specified sampling period.\n",
    "        \"\"\"\n",
    "        ### Argument validation\n",
    "        if sampling_period % self.frame_length != 0:\n",
    "            raise ValueError(\"Sampling period must be a multiple of 40ms.\")\n",
    "        \n",
    "        self.sampling_period = sampling_period\n",
    "        self.frame_spacing = int(self.sampling_period / self.frame_length) #Frames are 40 ms apart\n",
    "\n",
    "        ### Printing parameters\n",
    "        print(\"Filtering data with the following parameters:\")\n",
    "        print_green(f\"Sampling period: {self.sampling_period} ms\")\n",
    "        print_green(f\"Frame spacing: {self.frame_spacing} frames\")\n",
    "\n",
    "        ### Start framing scheme from 0\n",
    "        self.data['frame'] = self.data['frame'] - self.data['frame'].min()\n",
    "        self.data = self.data[self.data.frame % self.frame_spacing == 0]\n",
    "        self.raw_frames = deepcopy(self.data.frame) # copy the old frame numbering for animation purposes\n",
    "        self.data.frame = self.data.frame / self.frame_spacing\n",
    "        self.framing_dict = dict(zip(self.data.frame, self.raw_frames)) # create a dictionary to convert old frame numbering to new frame numbering\n",
    "\n",
    "        # Transform coordinate system\n",
    "        self.translate()\n",
    "        return self.data\n",
    "    \n",
    "    def translate(self) -> None:\n",
    "        \"\"\"\n",
    "        Translates the data to the center of the roundabout and performs a rotation to align the arms of the roundabout with the x-axis.\n",
    "\n",
    "        Adds new columns to the dataframe for the translated and rotated coordinates. Updates the entry and exit points as well.\n",
    "        \"\"\"\n",
    "        ### Error handling\n",
    "        if not hasattr(self, \"center_x_m\"):\n",
    "            raise ValueError(\"Please call the get_roundabout_edges method first.\")\n",
    "        if not hasattr(self, \"framing_dict\"):\n",
    "            raise ValueError(\"Please filter the data first.\")\n",
    "\n",
    "        # Translate the data to the center of the roundabout\n",
    "        self.data['xCenter_new'] = self.data['xCenter'] - self.center_x_m\n",
    "        self.data['yCenter_new'] = self.data['yCenter'] - self.center_y_m\n",
    "\n",
    "        # Rotate the data\n",
    "        angle = np.radians(self.rotation_angle)\n",
    "        print(f\"Rotating data {self.rotation_angle:.2f} degrees counterclockwise to align the roundabout arms with the x-axis.\")\n",
    "        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], \n",
    "                                    [np.sin(angle), np.cos(angle)]])\n",
    "        # Rotate positions\n",
    "        self.data['xCenter_new'], self.data['yCenter_new'] = np.dot(rotation_matrix, [self.data['xCenter_new'], self.data['yCenter_new']])\n",
    "        # Rotate velocities\n",
    "        self.data['xVelocity_new'], self.data['yVelocity_new'] = np.dot(rotation_matrix, [self.data['xVelocity'], self.data['yVelocity']])\n",
    "        # Rotate accelerations\n",
    "        self.data['xAcceleration_new'], self.data['yAcceleration_new'] = np.dot(rotation_matrix, [self.data['xAcceleration'], self.data['yAcceleration']])\n",
    "        # Update the entry and exit points\n",
    "        self.entry_points_m_new = {key: (point[0] - self.center_x_m, point[1] - self.center_y_m) for key, point in self.entry_points_m.items()}\n",
    "        self.exit_points_m_new = {key: (point[0] - self.center_x_m, point[1] - self.center_y_m) for key, point in self.exit_points_m.items()}\n",
    "        self.entry_points_m_new = {key: (point[0]*np.cos(angle) - point[1]*np.sin(angle), point[0]*np.sin(angle) + point[1]*np.cos(angle)) for key, point in self.entry_points_m_new.items()}\n",
    "        self.exit_points_m_new = {key: (point[0]*np.cos(angle) - point[1]*np.sin(angle), point[0]*np.sin(angle) + point[1]*np.cos(angle)) for key, point in self.exit_points_m_new.items()}\n",
    "            \n",
    "   \n",
    "    def get_ego_vehicles(self, entry_radius: Union[float, int] = 5.0, exit_radius: Union[float, int] = 5.0, min_gap: int = 10) -> None:\n",
    "        \"\"\"\n",
    "        Identifies vehicles entering and exiting the roundabout, recording their entry/exit frames and points.\n",
    "\n",
    "        This method calculates the Euclidean distance between each vehicle's position and all entry and exit points \n",
    "        of the roundabout. If a vehicle is within the specified `entry_radius` of an entry point and has not yet \n",
    "        entered the roundabout (checked via the `in_roundabout` method), it is considered entering. Similarly, \n",
    "        if a vehicle is near an exit point and has left the roundabout (checked via `in_roundabout`), it is considered exiting.\n",
    "\n",
    "        An additional check is performed to avoid false positives, where a vehicle may be detected near an exit point right\n",
    "        after entering the roundabout. The `min_gap` parameter specifies the minimum number of frames between entry and exit.\n",
    "\n",
    "        The method stores the result in the `self.ego_vehicles` dictionary, where each vehicle ID is mapped \n",
    "        to a tuple containing the first and last frame in which the vehicle is detected near the roundabout, \n",
    "        the entry point, and the exit point.\n",
    "\n",
    "        Args:\n",
    "            entry_radius (Union[float, int]): The radius around the entry points to consider for proximity (in meters). Default is 5.0.\n",
    "            exit_radius (Union[float, int]): The radius around the exit points to consider for proximity (in meters). Default is 5.0.\n",
    "            min_gap (int): The minimum number of frames between the entry and exit of a vehicle. Default is 10.\n",
    "\n",
    "        Returns:\n",
    "            self.ego_vehicles (Dict[int, Tuple[int, int, str, str]]): A dictionary where:\n",
    "                - The keys are vehicle IDs (int).\n",
    "                - The values are tuples of the form (first_frame, last_frame, entry_point, exit_point), where:\n",
    "                    - first_frame (int) is the frame when the vehicle was first detected near the entry point.\n",
    "                    - last_frame (int) is the frame when the vehicle was last detected near the exit point.\n",
    "                    - entry_point (str) is the name of the entry point the vehicle used ('north', 'south', 'east', or 'west').\n",
    "                    - exit_point (str) is the name of the exit point the vehicle used ('north', 'south', 'east', or 'west').\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `entry_points_m_new` or `framing_dict` are not set, which are prerequisites for this method.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"entry_points_m_new\"):\n",
    "            raise ValueError(\"Please call the translate method first.\")\n",
    "        if not hasattr(self, \"framing_dict\"):\n",
    "            raise ValueError(\"Please filter the data first.\")\n",
    "        \n",
    "        entry_radius = float(entry_radius)\n",
    "        exit_radius = float(exit_radius)\n",
    "        self.entry_radius_px = int(entry_radius / self.bg_image_scaling_factor)\n",
    "        self.exit_radius_px = int(exit_radius / self.bg_image_scaling_factor)\n",
    "        \n",
    "        # Extract necessary columns as numpy arrays for vectorized computation\n",
    "        vehicle_ids = self.data['trackId'].values\n",
    "        frames = self.data['frame'].values\n",
    "        x_positions = self.data['xCenter_new'].to_numpy()\n",
    "        y_positions = self.data['yCenter_new'].to_numpy()\n",
    "        \n",
    "        # Combine positions into a single array for efficient computation\n",
    "        vehicle_positions = np.vstack((x_positions, y_positions)).T  # Shape: (num_vehicles, 2)\n",
    "        \n",
    "        # Loop over the entry points to calculate distances to all vehicles in one go\n",
    "        for entry_name, entry_point in self.entry_points_m_new.items():\n",
    "            entry_point_array = np.array(entry_point)\n",
    "            \n",
    "            # Calculate the Euclidean distance between each vehicle and the current entry point\n",
    "            distances = np.linalg.norm(vehicle_positions - entry_point_array, axis=1)\n",
    "            \n",
    "            # Create a mask for vehicles within the entry radius\n",
    "            within_radius_mask = distances < entry_radius\n",
    "            \n",
    "            # Filter vehicle IDs, frames, and positions that are within the entry radius\n",
    "            candidate_vehicle_ids = vehicle_ids[within_radius_mask]\n",
    "            candidate_frames = frames[within_radius_mask]\n",
    "            candidate_positions = vehicle_positions[within_radius_mask]\n",
    "            \n",
    "            # Add vehicles only if they are not already inside the roundabout\n",
    "            for vehicle_id, frame, position in zip(candidate_vehicle_ids, candidate_frames, candidate_positions):\n",
    "                if vehicle_id not in self.ego_vehicles:\n",
    "                    #Check vehicle class - skip VRUs\n",
    "                    if self.vehicle_type[int(vehicle_id)] in self.restricted_vehicle_types:\n",
    "                        print(f\"Skipping VRU {vehicle_id} - Type: {self.vehicle_type[int(vehicle_id)]}\")\n",
    "                    # Check if the vehicle is already in the roundabout using the in_roundabout method\n",
    "                    if not self.in_roundabout(*position):\n",
    "                        # Initialize the ego vehicle with the first frame and entry point\n",
    "                        self.ego_vehicles[int(vehicle_id)] = [int(frame), None, entry_name, None]\n",
    "\n",
    "        # Loop over the exit points to track when the vehicle exits\n",
    "        for exit_name, exit_point in self.exit_points_m_new.items():\n",
    "            exit_point_array = np.array(exit_point)\n",
    "            \n",
    "            # Calculate the Euclidean distance between each vehicle and the current exit point\n",
    "            distances = np.linalg.norm(vehicle_positions - exit_point_array, axis=1)\n",
    "            \n",
    "            # Create a mask for vehicles within the exit radius\n",
    "            within_exit_radius_mask = distances < exit_radius\n",
    "            \n",
    "            # Filter vehicle IDs, frames, and positions that are within the exit radius\n",
    "            candidate_vehicle_ids = vehicle_ids[within_exit_radius_mask]\n",
    "            candidate_frames = frames[within_exit_radius_mask]\n",
    "            candidate_positions = vehicle_positions[within_exit_radius_mask]\n",
    "            \n",
    "            # Update vehicles with their exit point and last frame, only if they have left the roundabout and min_gap is satisfied\n",
    "            for vehicle_id, frame, position in zip(candidate_vehicle_ids, candidate_frames, candidate_positions):\n",
    "                if vehicle_id in self.ego_vehicles and not self.in_roundabout(*position) and frame - self.ego_vehicles[int(vehicle_id)][0] > min_gap:\n",
    "                    # Update the ego vehicle with the last frame and exit point\n",
    "                    self.ego_vehicles[int(vehicle_id)][1] = int(frame)  # Update last frame\n",
    "                    self.ego_vehicles[int(vehicle_id)][3] = exit_name   # Update exit point\n",
    "\n",
    "        # Sort the entry vehicles by their entry frame\n",
    "        self.ego_vehicles = dict(sorted(self.ego_vehicles.items(), key=lambda item: item[1][0]))\n",
    "        print(\"Number of ego vehicles detected:\", len(self.ego_vehicles))\n",
    "        # Print the number of entries in the dictionary that have a None value in any field\n",
    "        print(\"Number of incomplete ego vehicles:\", sum([None in ego_vehicle for ego_vehicle in self.ego_vehicles.values()]))\n",
    "\n",
    "    def get_groups(self) -> None:\n",
    "        \"\"\"\n",
    "        Forms vehicle groups based on the presence of vehicles between the entry and exit frames of each ego vehicle.\n",
    "\n",
    "        For each ego vehicle, this method collects every vehicle present in the frames between its entry and exit frames,\n",
    "        including the ego vehicle itself. The method returns a list of dataframes, where each dataframe represents a group\n",
    "        of vehicles present in the specified time window for a particular ego vehicle.\n",
    "        \"\"\"\n",
    "        self.groups = []\n",
    "        self.ego_vehicle_indices = []\n",
    "        skip_count = 0\n",
    "        # Iterate through the ego vehicles\n",
    "        for ego_id, (entry_frame, exit_frame, entry_point, exit_point) in self.ego_vehicles.items():\n",
    "            group_df = None\n",
    "            #Skip incomplete groups\n",
    "            if exit_frame is None:\n",
    "                skip_count += 1\n",
    "                continue\n",
    "            # Filter the data to include all vehicles present between entry_frame and exit_frame\n",
    "            group_df = self.data[(self.data['frame'] >= entry_frame) & (self.data['frame'] <= exit_frame)].copy()\n",
    "            if group_df.empty:\n",
    "                print(\"Skipping empty dataframe - Info:\", ego_id, entry_frame, exit_frame, entry_point, exit_point)\n",
    "\n",
    "            self.groups.append(group_df)\n",
    "            self.ego_vehicle_indices.append(ego_id)\n",
    "        print(f\"Skipped groups: {skip_count}\")\n",
    "        print(f\"Valid groups: {len(self.groups)}\")\n",
    "\n",
    "    def save_groups(self, save_path: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Saves the vehicle groups and ego vehicles to separate JSON files.\n",
    "\n",
    "        Args:\n",
    "            save_path (str): The directory path where the JSON files should be saved.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If no save path is provided.\n",
    "            FileNotFoundError: If the specified directory does not exist.\n",
    "            RuntimeError: If no groups have been created.\n",
    "        \"\"\"\n",
    "        if save_path is None:\n",
    "            raise ValueError(\"Please provide a save path for the JSON file.\")\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            raise FileNotFoundError(f\"The directory {save_path} does not exist.\")\n",
    "        \n",
    "        if not self.groups:\n",
    "            raise RuntimeError(\"No groups to save. Please run the group creation pipeline first.\")\n",
    "\n",
    "        # Prepare dictionary for group JSON content\n",
    "        json_dict = {}\n",
    "        for i, group in enumerate(self.groups):\n",
    "            json_dict[f'group_{i}'] = group.to_json(orient='records')\n",
    "\n",
    "        # Save groups to a JSON file\n",
    "        group_file_path = os.path.join(save_path, f\"groups_{self.dataset_index}.json\")\n",
    "        with open(group_file_path, 'w') as f:\n",
    "            json.dump(json_dict, f, indent=4)\n",
    "\n",
    "        # Save ego vehicles to a separate JSON file\n",
    "        ego_file_path = os.path.join(save_path, f\"ego_vehicles_{self.dataset_index}.json\")\n",
    "        with open(ego_file_path, 'w') as f:\n",
    "            json.dump(self.ego_vehicles, f, indent=4)\n",
    "\n",
    "        print(f\"Groups saved to {group_file_path}\")\n",
    "        print(f\"Ego vehicles saved to {ego_file_path}\")\n",
    "\n",
    "    def print_info(self):\n",
    "        \"\"\"Prints information for debugging purposes.\"\"\"\n",
    "        \n",
    "        print_blue(\"Dataset Information:\")\n",
    "        print(f\"Dataset location: {self.dataset_location}\")\n",
    "        print(f\"Dataset index: {self.dataset_index}\")\n",
    "        \n",
    "        print_blue(\"Group Information:\")\n",
    "        print(f\"Number of groups: {len(self.groups)}\")\n",
    "        \n",
    "        print_blue(\"Frame Information:\")\n",
    "        print(f\"Frame length: {self.frame_length} ms\")\n",
    "        print(f\"Sampling period: {self.sampling_period} ms\")\n",
    "        print(f\"Frame spacing: {self.frame_spacing} frames\")\n",
    "\n",
    "        print_blue(\"Roundabout geometry and entry/exit points:\")\n",
    "        print(f\"Roundabout center: ({self.center_x_m:.2f}, {self.center_y_m:.2f}) m\")\n",
    "        print(f\"Roundabout outer radius: {self.outer_radius_m:.2f} m\")\n",
    "        print(f\"Roundabout inner radius: {self.inner_radius_m:.2f} m\")\n",
    "        \n",
    "        print_green(\"Entry points: old -> new\")\n",
    "        for key, point in self.entry_points_m_new.items():\n",
    "            print(f\"{key}: ({self.entry_points_m[key][0]:.2f}, {self.entry_points_m[key][1]:.2f}) m -> ({point[0]:.2f}, {point[1]:.2f}) m\")\n",
    "        \n",
    "        print_green(\"Exit points: old -> new\")\n",
    "        for key, point in self.exit_points_m_new.items():\n",
    "            print(f\"{key}: ({self.exit_points_m[key][0]:.2f}, {self.exit_points_m[key][1]:.2f}) m -> ({point[0]:.2f}, {point[1]:.2f}) m\")\n",
    "\n",
    "    def plot_roundabout_geometry_and_points(self, rotate: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Plots the roundabout geometry, including the inner and outer edges, and marks the entry/exit points.\n",
    "\n",
    "        Args:\n",
    "            rotate (bool): If True, rotates the image to align the roundabout arms with the x-axis.\n",
    "\n",
    "        This method displays the background image with overlaid roundabout geometry, including the center, \n",
    "        inner and outer edges, and entry/exit points. Entry points are marked in red and exit points in blue.\n",
    "        \"\"\"\n",
    "        ## Error handling\n",
    "        if not hasattr(self, \"center_x_px\"):\n",
    "            raise ValueError(\"Please call the get_roundabout_edges method first.\")\n",
    "        if not hasattr(self, \"entry_points_px\"):\n",
    "            raise ValueError(\"Please call the get_entry_exit_points method first.\")\n",
    "        if not hasattr(self, \"rotation_angle\"):\n",
    "            raise ValueError(\"Please call the translate method first.\")\n",
    "        if not hasattr(self, \"entry_radius_px\"):\n",
    "            raise ValueError(\"Please call the get_ego_vehicles method first.\")\n",
    "\n",
    "        # Draw final roundabout geometry and entry/exit points\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        result_image = self.bg_image.copy()\n",
    "        cv2.circle(result_image, (self.center_x_px, self.center_y_px), self.outer_radius_px, (0, 255, 0), 4)  # Outer circle\n",
    "        cv2.circle(result_image, (self.center_x_px, self.center_y_px), self.inner_radius_px, (255, 0, 0), 4)  # Inner circle\n",
    "        cv2.circle(result_image, (self.center_x_px, self.center_y_px), 5, (0, 0, 255), -1)  # Center point\n",
    "\n",
    "        # Mark entry and exit points\n",
    "        for point in self.exit_points_px.values():\n",
    "            cv2.circle(result_image, tuple(np.int32(point)), 10, (255, 0, 0), -1)  # Blue for exit points - colors in BGR format\n",
    "            cv2.circle(result_image, tuple(np.int32(point)), self.exit_radius_px, (0, 0, 255), -1)  # Blue for exit points - colors in BGR format\n",
    "        for point in self.entry_points_px.values():\n",
    "            cv2.circle(result_image, tuple(np.int32(point)), 10, (0, 0, 255), -1)  # Red for exit points - colors in BGR format        \n",
    "            cv2.circle(result_image, tuple(np.int32(point)), self.entry_radius_px, (0, 0, 255), -1)  # Red for exit points - colors in BGR format        \n",
    "\n",
    "        # Rotate the image if specified\n",
    "        if rotate:\n",
    "            w,h = result_image.shape[1], result_image.shape[0]\n",
    "            M = cv2.getRotationMatrix2D((w/2,h/2), self.rotation_angle, 1)\n",
    "            result_image = cv2.warpAffine(result_image, M, (w,h))\n",
    "            \n",
    "        # Display the final image with the geometry and points\n",
    "        plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Roundabout Geometry with Entry (Red) and Exit (Blue) Points\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RounD Group extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing dataset <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing dataset \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Filtering data with the following parameters:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Filtering data with the following parameters:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling period: 400 ms\u001b[0m "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFrame spacing: 10 frames\u001b[0m "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Rotating data <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.40</span> degrees counterclockwise to align the roundabout arms with the x-axis.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Rotating data \u001b[1;36m14.40\u001b[0m degrees counterclockwise to align the roundabout arms with the x-axis.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Skipping VRU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> - Type: bicycle\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Skipping VRU \u001b[1;36m0\u001b[0m - Type: bicycle\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Skipping VRU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> - Type: bicycle\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Skipping VRU \u001b[1;36m2\u001b[0m - Type: bicycle\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Skipping VRU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> - Type: bicycle\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Skipping VRU \u001b[1;36m3\u001b[0m - Type: bicycle\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Skipping VRU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> - Type: bicycle\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Skipping VRU \u001b[1;36m7\u001b[0m - Type: bicycle\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Number of ego vehicles detected: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">565</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Number of ego vehicles detected: \u001b[1;36m565\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Number of incomplete ego vehicles: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Number of incomplete ego vehicles: \u001b[1;36m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Skipped groups: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Skipped groups: \u001b[1;36m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Valid groups: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">556</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Valid groups: \u001b[1;36m556\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Groups saved to .<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">groups_2.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Groups saved to .\u001b[35m/\u001b[0m\u001b[95mgroups_2.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ego vehicles saved to .<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">ego_vehicles_2.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ego vehicles saved to .\u001b[35m/\u001b[0m\u001b[95mego_vehicles_2.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Argument 'radius' is required to be an integer\n>  - Argument 'radius' is required to be an integer\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m scene_data\u001b[38;5;241m.\u001b[39mget_groups()\n\u001b[1;32m     12\u001b[0m scene_data\u001b[38;5;241m.\u001b[39msave_groups(save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mscene_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_roundabout_geometry_and_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 528\u001b[0m, in \u001b[0;36mRounDGroupExtractor.plot_roundabout_geometry_and_points\u001b[0;34m(self, rotate)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_points_px\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    527\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mcircle(result_image, \u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39mint32(point)), \u001b[38;5;241m10\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Blue for exit points - colors in BGR format\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit_radius_px\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Blue for exit points - colors in BGR format\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentry_points_px\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    530\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mcircle(result_image, \u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39mint32(point)), \u001b[38;5;241m10\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Red for exit points - colors in BGR format        \u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Argument 'radius' is required to be an integer\n>  - Argument 'radius' is required to be an integer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.exists(\"/Users/lmiguelmartinez/Tesis/datasets/rounD/data/\"):\n",
    "    dataset_location = \"/Users/lmiguelmartinez/Tesis/datasets/rounD/data/\"\n",
    "else:\n",
    "    dataset_location = \"/home/lmmartinez/Tesis/datasets/rounD/data/\"\n",
    "\n",
    "dataset_index = 2\n",
    "print(\"Processing dataset\", dataset_index)\n",
    "scene_data = RounDGroupExtractor(dataset_location=dataset_location, dataset_index=dataset_index)\n",
    "scene_data.filter_data(sampling_period=400)\n",
    "scene_data.get_ego_vehicles(entry_radius=5, exit_radius=5, min_gap=10)\n",
    "scene_data.get_groups()\n",
    "scene_data.save_groups(save_path=\"./\")\n",
    "scene_data.plot_roundabout_geometry_and_points(rotate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
