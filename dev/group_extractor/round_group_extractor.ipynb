{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Global imports\n",
    "import csv\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Typing import\n",
    "from typing import List, Dict, Union, Tuple\n",
    "\n",
    "# Specific imports\n",
    "from copy import deepcopy\n",
    "from matplotlib.patches import Rectangle, Ellipse\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from rich import print\n",
    "from termcolor import cprint\n",
    "from time import time\n",
    "\n",
    "# Local imports\n",
    "from read_csv import read_meta_info\n",
    "\n",
    "sns.set_theme('notebook')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.color_palette(\"hls\", 8)\n",
    "\n",
    "def print_bl():\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_red(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"red\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n",
    "\n",
    "def print_green(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"green\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n",
    "\n",
    "def print_highlight(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"magenta\", \"on_white\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n",
    "\n",
    "def print_blue(*args):\n",
    "    for arg in args:\n",
    "        cprint(arg, \"light_blue\", end=' ')  # Using end=' ' to print all arguments on the same line\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group definition:\n",
    "- 1 second sampling rate.\n",
    "- In any scene, choose an ego vehicle __outside__ of the roundabout. That is the ego vehicle.\n",
    "    - Sample the database until the ego vehicle enters the roundabout\n",
    "    - If window length is short, resample the same scene with another ego_vehicle. If there are not any suitable vehicles, move on.\n",
    "- Max window length: 5 seconds.\n",
    "\n",
    "Refer all coordinates to the center of the roundabout. Perform calculations in pixels and then convert to meters using OrthoPxToMeter*10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RounDGroupExtractor:\n",
    "    \"\"\"\n",
    "    A class that extracts vehicle groups from a highD dataset recording\n",
    "    \n",
    "    Attributes:\n",
    "        dataset_location: a path to the directory in which the dataset is stored.\n",
    "        dataset_index: index of the recording that is to be addressed\n",
    "        data: the raw data of the recording.\n",
    "        static_info: the static information of the recording.\n",
    "        video_info: the video information of the recording.\n",
    "\n",
    "    Methods:        \n",
    "        get_background_img: sets the background image for plotting, creating gifs, and calculating roundabout geometry.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_location: str = None, dataset_index: int = None):\n",
    "        \"\"\"\n",
    "        Initializes the PromptExtractor class.\n",
    "\n",
    "        Args:\n",
    "            dataset_location (str): The path to the directory in which the dataset is stored.\n",
    "            dataset_index (int): The index of the recording that is to be addressed.\n",
    "        \"\"\"\n",
    "        ### Error handling\n",
    "        if dataset_location is None:\n",
    "            raise ValueError(\"Please provide a dataset location.\")\n",
    "        if dataset_index is None or dataset_index < 1 or dataset_index > 22:\n",
    "            raise ValueError(\"Please provide a dataset index between 1 and 22\")\n",
    "        \n",
    "        # retrieve raw data\n",
    "        self.dataset_index  = dataset_index\n",
    "        self.dataset_location = dataset_location\n",
    "        self.df_location = dataset_location + str(dataset_index).zfill(2) + \"_tracks.csv\"\n",
    "        self.static_info_location = dataset_location + str(dataset_index).zfill(2) + \"_tracksMeta.csv\"\n",
    "        self.video_info_location = dataset_location + str(dataset_index).zfill(2) + \"_recordingMeta.csv\"\n",
    "        self.reference_image_path = dataset_location + '00_background.png'\n",
    "        self.image_path = dataset_location + f'{str(dataset_index).zfill(2)}_background.png'\n",
    "\n",
    "        self.reference_exit_points = {'north': (961,238), 'south': (645, 695), 'east': (1053, 590), 'west': (550, 354)}\n",
    "        self.reference_entry_points = {'north': (880, 195), 'south': (724, 735), 'east': (1083, 503), 'west': (528, 439)}\n",
    "        \n",
    "        def csv_to_dict(filename: str) -> Dict[str, Union[int, float, str]]:\n",
    "            def convert_value(value: str) -> Union[int, float, str]:\n",
    "                \"\"\"Helper function to convert values to the appropriate data type.\"\"\"\n",
    "                try:\n",
    "                    # Try to convert to an integer\n",
    "                    if '.' not in value:\n",
    "                        return int(value)\n",
    "                    # Try to convert to a float if it's not an int\n",
    "                    return float(value)\n",
    "                except ValueError:\n",
    "                    # If it fails to convert, return as string\n",
    "                    return value\n",
    "                \n",
    "            with open(filename, mode='r') as csv_file:\n",
    "                csv_reader = csv.DictReader(csv_file)\n",
    "                first_row = next(csv_reader)\n",
    "                return {key: convert_value(value) for key, value in first_row.items()}\n",
    "                \n",
    "        self.data = pd.read_csv(self.df_location)\n",
    "        self.static_info = pd.read_csv(self.static_info_location)\n",
    "        self.video_info = csv_to_dict(self.video_info_location)\n",
    "\n",
    "        self.frame_length = 1000/self.video_info[\"frameRate\"] # Measured in miliseconds\n",
    "\n",
    "        self.get_background_img(self.image_path)\n",
    "        self.center_x_px, self.center_y_px, self.outer_radius_px, self.inner_radius_px = self.get_roundabout_edges()\n",
    "        self.entry_points_px, self.exit_points_px = self.get_entry_exit_points()\n",
    "\n",
    "        # Convert pixel values to meters\n",
    "        self.center_x_m = self.center_x_px * self.bg_image_scaling_factor * 10\n",
    "        self.center_y_m = -self.center_y_px * self.bg_image_scaling_factor * 10\n",
    "        self.outer_radius_m = self.outer_radius_px * self.bg_image_scaling_factor * 10\n",
    "        self.inner_radius_m = self.inner_radius_px * self.bg_image_scaling_factor * 10\n",
    "        self.entry_points_m = {key: (point[0] * self.bg_image_scaling_factor * 10, -point[1] * self.bg_image_scaling_factor * 10) for key, point in self.entry_points_px.items()}\n",
    "        self.exit_points_m = {key: (point[0] * self.bg_image_scaling_factor * 10, -point[1] * self.bg_image_scaling_factor * 10) for key, point in self.exit_points_px.items()}\n",
    "\n",
    "        # print_green(f\"Roundabout center: ({self.center_x_m:.2f}, {self.center_y_m:.2f}) m\")\n",
    "        # print_green(f\"Roundabout outer radius: {self.outer_radius_m:.2f} m\")\n",
    "        # print_green(f\"Roundabout inner radius: {self.inner_radius_m:.2f} m\")\n",
    "\n",
    "        ## Initialize parameters\n",
    "        self.sampling_period = None\n",
    "        self.frame_spacing = None\n",
    "        self.raw_frames = None\n",
    "        self.framing_dict = None\n",
    " \n",
    "    def get_background_img(self, path) -> None:\n",
    "        '''\n",
    "        Sets the background image for plotting and creating gifs.\n",
    "            Parameters:\n",
    "                path (str): path to the png file that contains the background image\n",
    "            Returns:\n",
    "                Nothing\n",
    "        '''\n",
    "        self.bg_image = cv2.imread(path)\n",
    "        self.bg_image_scaling_factor = self.video_info[\"orthoPxToMeter\"] # Measured in meters per pixel\n",
    "\n",
    "    def get_roundabout_edges(self) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"\n",
    "        Detects both the outer and inner edges of the roundabout using HoughCircles.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: center_x, center_y, outer_radius, inner_radius\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(self.bg_image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 7), 0)\n",
    "\n",
    "        # Use HoughCircles to detect the roundabout's outer edge\n",
    "        outer_circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=1000,\n",
    "            param1=100, param2=30, minRadius=200, maxRadius=300\n",
    "        )\n",
    "\n",
    "        if outer_circles is not None:\n",
    "            outer_circles = np.round(outer_circles[0, :]).astype(\"int\")\n",
    "            largest_circle = max(outer_circles, key=lambda x: x[2])  # Select the largest circle (outer edge)\n",
    "            center_x, center_y, outer_radius = largest_circle\n",
    "\n",
    "            # Detect inner edge using a smaller radius range\n",
    "            inner_circles = cv2.HoughCircles(\n",
    "                blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=300,\n",
    "                param1=100, param2=30, minRadius=100, maxRadius=outer_radius - 50\n",
    "            )\n",
    "\n",
    "            if inner_circles is not None:\n",
    "                inner_circles = np.round(inner_circles[0, :]).astype(\"int\")\n",
    "                inner_center_x, inner_center_y, inner_radius = min(inner_circles, key=lambda x: abs(x[0] - center_x))\n",
    "                return center_x, center_y, outer_radius, inner_radius\n",
    "\n",
    "        raise ValueError(\"No outer or inner edge detected.\")\n",
    "\n",
    "    def get_entry_exit_points(self) -> Tuple[Dict[str, Tuple[int, int]], Dict[str, Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Calculates the entry and exit points of the roundabout based on homography.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Two dictionaries containing the entry and exit points.\n",
    "        \"\"\"\n",
    "        reference_image = cv2.imread(self.reference_image_path)\n",
    "        current_image = cv2.imread(self.image_path)\n",
    "\n",
    "        gray_reference = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)\n",
    "        gray_current = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Feature matching with SIFT\n",
    "        sift = cv2.SIFT_create()\n",
    "        kp_ref, des_ref = sift.detectAndCompute(gray_reference, None)\n",
    "        kp_cur, des_cur = sift.detectAndCompute(gray_current, None)\n",
    "\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        matches = bf.match(des_ref, des_cur)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        ref_pts = np.float32([kp_ref[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        cur_pts = np.float32([kp_cur[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Compute homography matrix\n",
    "        H, _ = cv2.findHomography(ref_pts, cur_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        reference_entry_points = np.float32(list(self.reference_entry_points.values())).reshape(-1, 1, 2)\n",
    "        reference_exit_points = np.float32(list(self.reference_exit_points.values())).reshape(-1, 1, 2)\n",
    "\n",
    "        transformed_entry_points = cv2.perspectiveTransform(reference_entry_points, H)\n",
    "        transformed_exit_points = cv2.perspectiveTransform(reference_exit_points, H)\n",
    "\n",
    "        entry_points = {key: tuple(point[0]) for key, point in zip(self.reference_entry_points.keys(), transformed_entry_points)}\n",
    "        exit_points = {key: tuple(point[0]) for key, point in zip(self.reference_exit_points.keys(), transformed_exit_points)}\n",
    "\n",
    "        return entry_points, exit_points\n",
    "\n",
    "    def plot_roundabout_geometry_and_points(self, plot_process: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Plots the roundabout geometry and entry/exit points, optionally showing the process (grayscale, blurred, etc.).\n",
    "\n",
    "        Args:\n",
    "            plot_process (bool): If True, plot the intermediate steps. If False, plot only the final results.\n",
    "        \"\"\"\n",
    "        ## Error handling\n",
    "        if not hasattr(self, \"center_x_px\"):\n",
    "            raise ValueError(\"Please call the get_roundabout_edges method first.\")\n",
    "        if not hasattr(self, \"entry_points_px\"):\n",
    "            raise ValueError(\"Please call the get_entry_exit_points method first.\")\n",
    "        \n",
    "        # Plot intermediate steps if required\n",
    "        if plot_process:\n",
    "            gray = cv2.cvtColor(self.bg_image, cv2.COLOR_BGR2GRAY)\n",
    "            blurred = cv2.GaussianBlur(gray, (9, 7), 0)\n",
    "\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "            axs[0, 0].imshow(cv2.cvtColor(self.bg_image, cv2.COLOR_BGR2RGB))\n",
    "            axs[0, 0].set_title('Original Image')\n",
    "\n",
    "            axs[0, 1].imshow(gray, cmap='gray')\n",
    "            axs[0, 1].set_title('Grayscale Image')\n",
    "\n",
    "            axs[1, 0].imshow(blurred, cmap='gray')\n",
    "            axs[1, 0].set_title('Blurred Image')\n",
    "\n",
    "        # Draw final roundabout geometry and entry/exit points\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        result_image = self.bg_image.copy()\n",
    "        cv2.circle(result_image, (self.center_x_px, self.center_y_px), self.outer_radius_px, (0, 255, 0), 4)  # Outer circle\n",
    "        cv2.circle(result_image, (self.center_x_px, self.center_y_px), self.inner_radius_px, (255, 0, 0), 4)  # Inner circle\n",
    "        cv2.circle(result_image, (self.center_x_px, self.center_y_px), 5, (0, 0, 255), -1)  # Center point\n",
    "\n",
    "        # Mark entry and exit points\n",
    "        for point in self.entry_points_px.values():\n",
    "            cv2.circle(result_image, tuple(np.int32(point)), 10, (255, 0, 0), -1)  # Red for entry points\n",
    "        for point in self.entry_points_px.values():\n",
    "            cv2.circle(result_image, tuple(np.int32(point)), 10, (0, 0, 255), -1)  # Blue for exit points\n",
    "\n",
    "        # Display the final image with the geometry and points\n",
    "        plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Roundabout Geometry with Entry (Red) and Exit (Blue) Points\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    def in_roundabout(self, x: float, y: float) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if a point is inside the roundabout.\n",
    "        \n",
    "        Args:\n",
    "            x (float): X-coordinate of the point.\n",
    "            y (float): Y-coordinate of the point.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if the point is inside the roundabout, False otherwise.\n",
    "        \"\"\"\n",
    "        distance_to_center = np.linalg.norm(np.array([x, y]) - np.array([self.center_x_m, self.center_y_m]))\n",
    "        return self.inner_radius_m <= distance_to_center <= self.outer_radius_m\n",
    "    \n",
    "    def filter_data(self, sampling_period: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filters the dataset with a certain sampling period.\n",
    "\n",
    "        Args:\n",
    "            sampling_period (int): The time spacing between each frame to consider. Measured in ms.\n",
    "        Returns:\n",
    "            The filtered dataset in the form of a pandas dataframe.\n",
    "        \"\"\"\n",
    "        ### Argument validation\n",
    "        if sampling_period % self.frame_length != 0:\n",
    "            raise ValueError(\"Sampling period must be a multiple of 40ms.\")\n",
    "        \n",
    "        self.sampling_period = sampling_period\n",
    "        self.frame_spacing = int(self.sampling_period / self.frame_length) #Frames are 40 ms apart\n",
    "\n",
    "        ### Printing parameters\n",
    "        print(\"Filtering data with the following parameters:\")\n",
    "        print_green(f\"Sampling period: {self.sampling_period} ms\")\n",
    "        print_green(f\"Frame spacing: {self.frame_spacing} frames\")\n",
    "\n",
    "        self.data = self.data[self.data.frame % self.frame_spacing == 0]\n",
    "        self.raw_frames = deepcopy(self.data.frame) # copy the old frame numbering for animation purposes\n",
    "        self.data.frame = self.data.frame / self.frame_spacing\n",
    "        self.framing_dict = dict(zip(self.data.frame, self.raw_frames)) # create a dictionary to convert old frame numbering to new frame numbering\n",
    "        self.data = self.data.astype({'frame': 'int16'})\n",
    "\n",
    "        return self.data\n",
    "    \n",
    "    def translate(self) -> None:\n",
    "        \"\"\"\n",
    "        Translates the data to the center of the roundabout and performs a rotation to align the arms of the roundabout with the x-axis.\n",
    "\n",
    "        From visual inspection, the data needs to be rotated 14.25 degrees counterclockwise.\n",
    "        \"\"\"\n",
    "        ### Error handling\n",
    "        if not hasattr(self, \"center_x_m\"):\n",
    "            raise ValueError(\"Please call the get_roundabout_edges method first.\")\n",
    "        if not hasattr(self, \"framing_dict\"):\n",
    "            raise ValueError(\"Please filter the data first.\")\n",
    "        \n",
    "        # Translate the x and y coordinates\n",
    "        self.data['x'] = self.data['x'] - self.center_x_m\n",
    "        self.data['y'] = self.data['y'] - self.center_y_m\n",
    "\n",
    "        # Rotate the data\n",
    "        angle = np.radians(14.25)\n",
    "        rotation_matrix = np.array([np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)])\n",
    "        self.data[['x', 'y']] = self.data[['x', 'y']].dot(rotation_matrix)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RounD Group extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing dataset <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing dataset \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "RounDGroupExtractor.get_roundabout_edges() got an unexpected keyword argument 'plot_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataset_index)\n\u001b[1;32m      9\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 10\u001b[0m scene_data \u001b[38;5;241m=\u001b[39m \u001b[43mRounDGroupExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime elapsed is:\u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m-\u001b[39m start)\n",
      "Cell \u001b[0;32mIn[11], line 66\u001b[0m, in \u001b[0;36mRounDGroupExtractor.__init__\u001b[0;34m(self, dataset_location, dataset_index)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframeRate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# Measured in miliseconds\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_background_img(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_path)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_x_px, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_y_px, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mouter_radius_px, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_radius_px \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_roundabout_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_x_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_x_px \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbg_image_scaling_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_y_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_y_px \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbg_image_scaling_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: RounDGroupExtractor.get_roundabout_edges() got an unexpected keyword argument 'plot_results'"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"/Users/lmiguelmartinez/Tesis/datasets/rounD/data/\"):\n",
    "    dataset_location = \"/Users/lmiguelmartinez/Tesis/datasets/rounD/data/\"\n",
    "else:\n",
    "    dataset_location = \"/home/lmmartinez/Tesis/datasets/rounD/data/\"\n",
    "\n",
    "#dataset_index = 3\n",
    "for dataset_index in range(1, 23):\n",
    "    print(\"Processing dataset\", dataset_index)\n",
    "    start = time()\n",
    "    scene_data = RounDGroupExtractor(dataset_location=dataset_location, dataset_index=dataset_index)\n",
    "    end = time()\n",
    "    print(\"Time elapsed is:\", end - start)\n",
    "    start = time()\n",
    "    scene_data.get_roundabout_edges()    \n",
    "    scene_data.get_entry_exit_points()\n",
    "    scene_data.plot_roundabout_geometry_and_points(plot_process=False)\n",
    "    start = time()\n",
    "    scene_data.filter_data(sampling_period=1000)\n",
    "    end = time()\n",
    "    start = time()\n",
    "    end = time()\n",
    "    print(\"Time elapsed is:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81.28121089327104</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-46.83829777724743</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.19717537691402</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.849836124187851</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m81.28121089327104\u001b[0m \u001b[1;36m-46.83829777724743\u001b[0m \u001b[1;36m25.19717537691402\u001b[0m \u001b[1;36m15.849836124187851\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scene_data.data.head()\n",
    "print(scene_data.center_x_m, scene_data.center_y_m, scene_data.outer_radius_m, scene_data.inner_radius_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
